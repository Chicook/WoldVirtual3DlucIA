#!/usr/bin/env python3
"""
Test Self Improvement - Script de Prueba del Sistema de Auto-mejora de LucIA
Prueba bÃ¡sica del sistema de auto-mejora integrado
"""

import sys
import logging
from pathlib import Path

# AÃ±adir el directorio padre al path para importar mÃ³dulos
current_dir = Path(__file__).parent
lucia_dir = current_dir.parent.parent.parent.parent  # Subir hasta lucIA/
sys.path.append(str(lucia_dir))

# Importar componentes del sistema
from lucia_learning.memoria.self_improvement.core.self_improvement import LucIASelfImprovement

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_self_improvement_system():
    """Prueba bÃ¡sica del sistema de auto-mejora"""
    print("ğŸ§ª Prueba del Sistema de Auto-mejora de LucIA")
    print("="*60)
    
    try:
        # 1. Probar clase principal
        print("\n1ï¸âƒ£ Probando clase principal LucIASelfImprovement...")
        improvement = LucIASelfImprovement()
        print("âœ… Clase principal inicializada correctamente")
        
        # 2. Probar anÃ¡lisis de cÃ³digo
        print("\n2ï¸âƒ£ Probando anÃ¡lisis de cÃ³digo...")
        analysis = improvement.analyze_current_code()
        
        if 'error' in analysis:
            print(f"âŒ Error en anÃ¡lisis: {analysis['error']}")
            return False
            
        print(f"âœ… AnÃ¡lisis completado: {analysis.get('files_analyzed', 0)} archivos analizados")
        
        # 3. Probar detecciÃ³n de mejoras
        print("\n3ï¸âƒ£ Probando detecciÃ³n de mejoras...")
        opportunities = improvement.detect_improvements(analysis)
        print(f"âœ… DetecciÃ³n completada: {len(opportunities)} oportunidades encontradas")
        
        # 4. Probar generaciÃ³n de mejoras
        print("\n4ï¸âƒ£ Probando generaciÃ³n de mejoras...")
        improvements = improvement.generate_improvements(opportunities)
        print(f"âœ… GeneraciÃ³n completada: {len(improvements)} mejoras generadas")
        
        # 5. Probar validaciÃ³n
        print("\n5ï¸âƒ£ Probando validaciÃ³n de mejoras...")
        validation = improvement.validate_improvements(improvements)
        valid_count = sum(1 for v in validation if v.get('is_valid', False))
        print(f"âœ… ValidaciÃ³n completada: {valid_count}/{len(validation)} mejoras vÃ¡lidas")
        
        # 6. Mostrar resultados
        print("\nğŸ“Š RESULTADOS DE LA PRUEBA:")
        print("="*40)
        
        metrics = analysis.get('general_metrics', {})
        if metrics:
            print(f"ğŸ“ Archivos analizados: {metrics.get('files_analyzed', 0)}")
            print(f"ğŸ“ LÃ­neas de cÃ³digo: {metrics.get('lines_of_code', 0):,}")
            print(f"ğŸ”§ Funciones encontradas: {metrics.get('functions', 0)}")
            print(f"ğŸ—ï¸ Clases encontradas: {metrics.get('classes', 0)}")
            print(f"ğŸ§  Complejidad promedio: {metrics.get('average_complexity', 0):.1f}")
            print(f"ğŸ“š DocumentaciÃ³n promedio: {metrics.get('average_documentation_coverage', 0):.1f}%")
            
        print(f"ğŸ’¡ Oportunidades detectadas: {len(opportunities)}")
        print(f"ğŸ› ï¸ Mejoras generadas: {len(improvements)}")
        print(f"âœ… Mejoras vÃ¡lidas: {valid_count}")
        
        # Mostrar algunas oportunidades
        if opportunities:
            print(f"\nğŸ¯ Oportunidades detectadas:")
            for i, opp in enumerate(opportunities[:3], 1):
                print(f"   {i}. {opp.get('description', 'Sin descripciÃ³n')} (Prioridad: {opp.get('priority', 'N/A')})")
                
        # Mostrar algunas mejoras
        if improvements:
            print(f"\nğŸ› ï¸ Mejoras generadas:")
            for i, imp in enumerate(improvements[:3], 1):
                print(f"   {i}. {imp.get('description', 'Sin descripciÃ³n')} (Confianza: {imp.get('confidence', 0):.2f})")
                
        print("\nğŸ‰ Â¡Prueba completada exitosamente!")
        return True
        
    except Exception as e:
        print(f"âŒ Error en la prueba: {e}")
        logger.error(f"Error en prueba: {e}")
        return False

def test_specific_improvements():
    """Prueba mejoras especÃ­ficas"""
    print("\nğŸ”§ Prueba de Mejoras EspecÃ­ficas")
    print("="*40)
    
    try:
        improvement = LucIASelfImprovement()
        
        # Probar mejora de mantenibilidad
        print("\nğŸ“Š Probando mejora de mantenibilidad...")
        results = improvement.run_specific_improvement('maintainability')
        if 'error' not in results:
            print(f"âœ… Mejora de mantenibilidad: {results.get('improvements_generated', 0)} mejoras generadas")
        else:
            print(f"âš ï¸ Mejora de mantenibilidad: {results.get('error', 'Error desconocido')}")
            
        # Probar mejora de documentaciÃ³n
        print("\nğŸ“š Probando mejora de documentaciÃ³n...")
        results = improvement.run_specific_improvement('documentation')
        if 'error' not in results:
            print(f"âœ… Mejora de documentaciÃ³n: {results.get('improvements_generated', 0)} mejoras generadas")
        else:
            print(f"âš ï¸ Mejora de documentaciÃ³n: {results.get('error', 'Error desconocido')}")
            
        return True
        
    except Exception as e:
        print(f"âŒ Error en prueba de mejoras especÃ­ficas: {e}")
        return False

def main():
    """FunciÃ³n principal de pruebas"""
    print("ğŸ§ª Sistema de Pruebas del Auto-mejora de LucIA")
    print("="*60)
    print(f"ğŸ“… Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Ejecutar pruebas
    tests = [
        ("Sistema Completo", test_self_improvement_system),
        ("Mejoras EspecÃ­ficas", test_specific_improvements)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            result = test_func()
            results.append((test_name, result))
            print(f"{'âœ… PASÃ“' if result else 'âŒ FALLÃ“'}: {test_name}")
        except Exception as e:
            print(f"âŒ ERROR: {test_name} - {e}")
            results.append((test_name, False))
            
    # Resumen final
    print(f"\n{'='*60}")
    print("ğŸ“Š RESUMEN DE PRUEBAS")
    print("="*60)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… PASÃ“" if result else "âŒ FALLÃ“"
        print(f"{status}: {test_name}")
        
    print(f"\nğŸ¯ Resultado Final: {passed}/{total} pruebas pasaron")
    
    if passed == total:
        print("ğŸ‰ Â¡Todas las pruebas pasaron exitosamente!")
        return 0
    else:
        print("âš ï¸ Algunas pruebas fallaron. Revisar errores.")
        return 1

if __name__ == "__main__":
    from datetime import datetime
    exit(main()) 